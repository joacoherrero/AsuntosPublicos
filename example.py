# Importaci√≥n de las clases necesarias del proyecto
from rss_reader import RSSReader
from collections import defaultdict
import re
import time
import pandas as pd
import concurrent.futures
from docx import Document
from docx.shared import Pt
from datetime import datetime
import os
import gspread
from google.oauth2.service_account import Credentials
import logging
import sys

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

def cargar_diccionario():
    """Carga los temas y palabras clave del diccionario Excel"""
    try:
        df = pd.read_excel('Diccionario.xlsx', engine='openpyxl')
        temas = {}
        
        # Iterar sobre las filas del DataFrame
        for _, row in df.iterrows():
            if pd.notna(row.iloc[0]):  # Si hay tema
                tema = str(row.iloc[0]).strip()
                if tema not in temas:
                    temas[tema] = {
                        'tema': tema,
                        'palabras_clave': []
                    }
                
                # Si hay palabra clave, agregarla
                if len(row) > 1 and pd.notna(row.iloc[1]):
                    palabra_clave = str(row.iloc[1]).strip().lower()
                    temas[tema]['palabras_clave'].append(palabra_clave)
        
        return temas
    except Exception as e:
        print(f"‚ùå Error al cargar el diccionario: {str(e)}")
        return {}

def cargar_noticias_sheets():
    """Carga las noticias del d√≠a desde Google Sheets"""
    try:
        print("\nüìä Intentando conectar con Google Sheets...")
        
        # Verificar si existe el archivo de credenciales
        if not os.path.exists('credentials.json'):
            print("‚ùå No se encontr√≥ el archivo credentials.json")
            return []
        
        # Configurar credenciales
        scopes = [
            'https://www.googleapis.com/auth/spreadsheets.readonly',
            'https://www.googleapis.com/auth/drive.readonly'
        ]
        
        print("üîë Cargando credenciales desde credentials.json...")
        try:
            credentials = Credentials.from_service_account_file('credentials.json', scopes=scopes)
            print("‚úÖ Credenciales cargadas correctamente")
        except Exception as e:
            print(f"‚ùå Error al cargar credenciales: {str(e)}")
            return []
        
        print("üîÑ Autorizando con Google...")
        try:
            gc = gspread.authorize(credentials)
            print("‚úÖ Autorizaci√≥n exitosa")
        except Exception as e:
            print(f"‚ùå Error en la autorizaci√≥n: {str(e)}")
            return []
        
        # ID de la hoja de c√°lculo - REEMPLAZA ESTE ID CON EL DE TU HOJA
        SPREADSHEET_ID = '1MwmcgWqaJzTimdsjvAyLNRZTKxqfqjG9o8PygxKeLrA'
        
        print(f"üìù Accediendo a la hoja de c√°lculo (ID: {SPREADSHEET_ID})...")
        try:
            spreadsheet = gc.open_by_key(SPREADSHEET_ID)
            print("‚úÖ Hoja de c√°lculo abierta correctamente")
        except gspread.exceptions.SpreadsheetNotFound:
            print("‚ùå No se encontr√≥ la hoja de c√°lculo con ese ID")
            return []
        except Exception as e:
            print(f"‚ùå Error al abrir la hoja de c√°lculo: {str(e)}")
            return []
        
        print("üìä Accediendo a la hoja 'Noticias'...")
        try:
            worksheet = spreadsheet.worksheet('Noticias')
            print("‚úÖ Hoja 'Noticias' encontrada")
        except gspread.exceptions.WorksheetNotFound:
            print("‚ùå No se encontr√≥ la hoja 'Noticias' en el documento")
            return []
        except Exception as e:
            print(f"‚ùå Error al acceder a la hoja 'Noticias': {str(e)}")
            return []
        
        print("üì• Leyendo datos...")
        try:
            data = worksheet.get_all_values()
            print(f"‚úÖ Se leyeron {len(data)} filas de datos")
        except Exception as e:
            print(f"‚ùå Error al leer los datos: {str(e)}")
            return []
        
        # Convertir a DataFrame
        df = pd.DataFrame(data[1:], columns=data[0])  # Asumiendo que la primera fila son los encabezados
        
        # Filtrar por la fecha de hoy
        fecha_hoy = datetime.now().strftime('%d/%m/%Y')
        print(f"üìÖ Filtrando noticias de hoy ({fecha_hoy})...")
        df_hoy = df[df['Fecha'] == fecha_hoy]
        
        # Convertir a formato de noticias
        noticias = []
        for _, row in df_hoy.iterrows():
            noticia = {
                'title': row['A'],  # T√≠tulo en columna A
                'feed_name': 'whatsapp_group',
                'published': row['Fecha'],
                'link': ''  # No hay link disponible
            }
            noticias.append(noticia)
        
        print(f"‚úÖ Google Sheets: {len(noticias)} noticias cargadas de hoy")
        return noticias
        
    except Exception as e:
        print(f"‚ùå Error al cargar noticias de Google Sheets: {str(e)}")
        print(f"Tipo de error: {type(e).__name__}")
        import traceback
        print("Detalles del error:")
        print(traceback.format_exc())
        return []

def procesar_feed(args):
    """Procesa un feed RSS individual"""
    name, url = args
    max_retries = 3
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            rss_reader = RSSReader()
            rss_reader.add_feed(name, url)
            entries = rss_reader.get_feed_entries(name, limit=50)
            if entries:
                print(f"‚úÖ {name}: {len(entries)} noticias cargadas")
                return name, entries
            else:
                print(f"‚ö†Ô∏è Advertencia: No se encontraron entradas en el feed {name}")
                return name, []
        except Exception as e:
            retry_count += 1
            if retry_count < max_retries:
                print(f"‚ö†Ô∏è Intento {retry_count} fallido para {name}: {str(e)}")
                time.sleep(2)
            else:
                print(f"‚ùå Error al procesar {name} despu√©s de {max_retries} intentos: {str(e)}")
                return name, []

def clasificar_noticia(noticia, temas):
    """Clasifica una noticia seg√∫n los temas del diccionario"""
    titulo = noticia['title'].lower()
    temas_encontrados = []
    
    for tema_data in temas.values():
        # Por cada palabra clave del tema, verificar si est√° contenida en el t√≠tulo
        for palabra_clave in tema_data['palabras_clave']:
            if palabra_clave in titulo:
                tema_encontrado = {
                    'tema': tema_data['tema'],
                    'palabra_encontrada': palabra_clave
                }
                logging.info(f"Noticia: '{noticia['title']}' clasificada en tema: '{tema_data['tema']}' por palabra clave: '{palabra_clave}'")
                temas_encontrados.append(tema_encontrado)
                break
    
    return temas_encontrados

def generar_lista_medios(feeds):
    """Genera una lista formateada de los medios utilizados"""
    medios = {
        'infobae': 'Infobae',
        'clarin': 'Clar√≠n',
        'lanacion_principal': 'La Naci√≥n',
        'lanacion_politica': 'La Naci√≥n - Pol√≠tica',
        'lanacion_economia': 'La Naci√≥n - Econom√≠a',
        'lanacion_deportes': 'La Naci√≥n - Deportes',
        'lanacion_sociedad': 'La Naci√≥n - Sociedad',
        'lanacion_mundo': 'La Naci√≥n - El Mundo',
        'lanacion_tecnologia': 'La Naci√≥n - Tecnolog√≠a',
        'lanacion_opinion': 'La Naci√≥n - Opini√≥n',
        'lanacion_lifestyle': 'La Naci√≥n - Lifestyle',
        'lagaceta_general': 'La Gaceta',
        'lagaceta_politica': 'La Gaceta - Pol√≠tica',
        'lagaceta_economia': 'La Gaceta - Econom√≠a',
        'lagaceta_deportes': 'La Gaceta - Deportes',
        'lagaceta_sociedad': 'La Gaceta - Sociedad',
        'lagaceta_mundo': 'La Gaceta - Mundo',
        'lagaceta_espectaculos': 'La Gaceta - Espect√°culos',
        'lagaceta_opinion': 'La Gaceta - Opini√≥n',
        'misiones_online': 'Misiones Online',
        'eldia': 'El D√≠a',
        'rionegro': 'R√≠o Negro',
        'diario_cuyo': 'Diario de Cuyo',
        'pagina12': 'P√°gina/12',
        'cronista': 'El Cronista',
        'tn': 'TN',
        'ambito_home': '√Åmbito Financiero',
        'ambito_economia': '√Åmbito - Econom√≠a',
        'ambito_ultimas': '√Åmbito - √öltimas Noticias',
        'ambito_politica': '√Åmbito - Pol√≠tica',
        'ambito_tecnologia': '√Åmbito - Tecnolog√≠a',
        'lavoz_principal': 'La Voz',
        'lavoz_noticias': 'La Voz - Noticias',
        'lavoz_politica': 'La Voz - Pol√≠tica',
        'lavoz_negocios': 'La Voz - Negocios',
        'lavoz_ciudadanos': 'La Voz - Ciudadanos',
        'lavoz_deportes': 'La Voz - Deportes',
        'lavoz_cultura': 'La Voz - Cultura',
        'lavoz_internacionales': 'La Voz - Internacionales',
        'lavoz_espectaculos': 'La Voz - Espect√°culos',
        'lavoz_opinion': 'La Voz - Opini√≥n'
    }
    
    # Obtener medios √∫nicos (sin secciones)
    medios_unicos = set()
    for feed_id in feeds.keys():
        # Obtener el nombre base del medio (antes del guion bajo)
        medio_base = feed_id.split('_')[0]
        if medio_base in medios:
            medios_unicos.add(medios[medio_base])
    
    return sorted(list(medios_unicos))

def guardar_en_word(noticias_por_tema, total_noticias, tiempo_total, feeds):
    """Guarda los resultados en un documento Word"""
    doc = Document()
    
    # Configurar el t√≠tulo
    titulo = doc.add_heading('Reporte de Noticias por Tema', 0)
    titulo.alignment = 1  # Centrado
    
    # Agregar informaci√≥n general
    doc.add_paragraph(f'Fecha del reporte: {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}')
    doc.add_paragraph(f'Total de noticias clasificadas: {total_noticias}')
    doc.add_paragraph(f'Tiempo de procesamiento: {tiempo_total:.2f} segundos')
    
    # Agregar lista de medios consultados
    doc.add_heading('Medios consultados:', level=1)
    medios_list = generar_lista_medios(feeds)
    for medio in medios_list:
        doc.add_paragraph(f'‚Ä¢ {medio}')
    
    # Agregar noticias por tema
    for tema, noticias in noticias_por_tema.items():
        if noticias:
            # Agregar encabezado del tema
            doc.add_heading(f'{tema} ({len(noticias)} noticias)', level=1)
            
            # Agregar cada noticia
            for noticia in noticias:
                p = doc.add_paragraph()
                p.add_run(f'‚Ä¢ {noticia["title"]}').bold = True
                p.add_run(f'\n  {noticia["feed_name"]} - {noticia.get("published", "Fecha no disponible")}')
                p.add_run(f'\n  Palabra clave encontrada: {noticia["palabra_encontrada"]}')
                p.add_run(f'\n  {noticia["link"]}')
                doc.add_paragraph()  # Espacio entre noticias
    
    # Crear directorio si no existe
    os.makedirs('Reportes', exist_ok=True)
    
    # Guardar el documento
    fecha_actual = datetime.now().strftime("%Y%m%d_%H%M%S")
    nombre_archivo = f'Reportes/reporte_noticias_{fecha_actual}.docx'
    doc.save(nombre_archivo)
    print(f"\n‚úÖ Reporte guardado como: {nombre_archivo}")

def cargar_cuentas():
    """Carga la informaci√≥n de cuentas y sus temas asociados desde el Excel"""
    try:
        logging.info("üìÇ Intentando abrir Cuentas.xlsx...")
        
        # Verificar si el archivo existe
        if not os.path.exists('Cuentas.xlsx'):
            logging.error("‚ùå El archivo Cuentas.xlsx no existe en el directorio actual")
            return {}
            
        # Intentar leer el archivo
        df = pd.read_excel('Cuentas.xlsx', engine='openpyxl')
        logging.info("‚úÖ Archivo abierto correctamente")
        
        if df.empty:
            logging.error("‚ùå El archivo est√° vac√≠o")
            return {}
            
        if 'Empresa' not in df.columns:
            logging.error("‚ùå El archivo no tiene la columna 'Empresa'")
            return {}
            
        logging.info(f"Columnas encontradas: {df.columns.tolist()}")
        
        # Diccionario para almacenar la relaci√≥n empresa -> temas
        cuentas = {}
        
        # Procesar cada fila (empresa)
        for idx, row in df.iterrows():
            try:
                empresa = row['Empresa']
                
                # Si no hay empresa, saltamos
                if pd.isna(empresa):
                    continue
                    
                empresa = str(empresa).strip()
                
                # Inicializar la empresa en el diccionario
                if empresa not in cuentas:
                    cuentas[empresa] = {
                        'nombre': empresa,
                        'temas': []
                    }
                
                # Procesar cada columna de tem√°ticas
                for columna in df.columns:
                    if columna != 'Empresa' and pd.notna(row[columna]):
                        tema = str(row[columna]).strip()
                        if tema and tema not in cuentas[empresa]['temas']:
                            logging.info(f"Empresa: {empresa} - Tema encontrado: '{tema}'")
                            cuentas[empresa]['temas'].append(tema)
                            
            except Exception as row_error:
                logging.error(f"Error procesando fila {idx}: {str(row_error)}")
                continue
        
        return cuentas
        
    except Exception as e:
        logging.error(f"‚ùå Error al cargar el archivo de cuentas: {str(e)}")
        import traceback
        logging.error("Detalles del error:")
        logging.error(traceback.format_exc())
        return {}

def guardar_reporte_cuenta(cuenta, temas_cuenta, noticias_por_tema, tiempo_total, feeds):
    """Guarda un reporte Word para una cuenta espec√≠fica"""
    try:
        # Crear directorio para reportes
        fecha_str = datetime.now().strftime("%Y%m%d")
        dir_reportes = os.path.join("Reportes", fecha_str)
        os.makedirs(dir_reportes, exist_ok=True)
        
        # Crear documento Word
        doc = Document()
        
        # T√≠tulo
        doc.add_heading(f'Reporte de Noticias - {cuenta}', 0)
        
        # Informaci√≥n general
        doc.add_paragraph(f'Fecha del reporte: {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}')
        doc.add_paragraph(f'Temas monitoreados: {", ".join(temas_cuenta)}')
        doc.add_paragraph(f'Medios relevados: {", ".join(generar_lista_medios(feeds))}')
        doc.add_paragraph()
        
        # Agregar noticias por tema
        for tema in temas_cuenta:
            if tema in noticias_por_tema and noticias_por_tema[tema]:
                doc.add_heading(f'üìå {tema.upper()}', level=1)
                doc.add_paragraph('_' * 80)
                
                for noticia in noticias_por_tema[tema]:
                    p = doc.add_paragraph()
                    p.add_run(f'‚Ä¢ {noticia["title"]}').bold = True
                    p.add_run(f'\n  {noticia["feed_name"]} - {noticia["published"]}')
                    if "palabra_encontrada" in noticia:
                        p.add_run(f'\n  Palabra clave encontrada: {noticia["palabra_encontrada"]}')
                    if "link" in noticia:
                        p.add_run(f'\n  {noticia["link"]}')
                    doc.add_paragraph()
        
        # Agregar contenido del Bolet√≠n Oficial si existe
        try:
            # Buscar el √∫ltimo reporte del BO
            dir_bo = "datos_boletin"
            if os.path.exists(dir_bo):
                # Encontrar la √∫ltima carpeta de reportes
                carpetas_reportes = [d for d in os.listdir(dir_bo) if d.endswith('_reportes_cuenta')]
                if carpetas_reportes:
                    ultima_carpeta = sorted(carpetas_reportes)[-1]
                    ruta_reporte_bo = os.path.join(dir_bo, ultima_carpeta, f"reporte_detallado_{cuenta.replace(' ', '_').replace('/', '_')}.docx")
                    
                    if os.path.exists(ruta_reporte_bo):
                        # Agregar separador
                        doc.add_heading('=' * 50, level=1)
                        doc.add_heading('DOCUMENTOS DEL BOLET√çN OFICIAL', level=1)
                        doc.add_paragraph('_' * 80)
                        
                        # Cargar el documento del BO
                        doc_bo = Document(ruta_reporte_bo)
                        
                        # Copiar el contenido desde despu√©s del t√≠tulo principal
                        for element in list(doc_bo.element.body)[2:]:  # Saltar t√≠tulo y fecha
                            doc.element.body.append(element)
                            
                        doc.add_paragraph(f"\nInformaci√≥n extra√≠da del reporte: {ruta_reporte_bo}")
                        
        except Exception as e:
            doc.add_paragraph(f"\nNota: No se pudo incluir informaci√≥n del Bolet√≠n Oficial. Error: {str(e)}")
        
        # Guardar documento
        nombre_archivo = f"reporte_{cuenta.replace(' ', '_')}_{datetime.now().strftime('%H%M%S')}.docx"
        ruta_archivo = os.path.join(dir_reportes, nombre_archivo)
        doc.save(ruta_archivo)
        
        print(f"‚úÖ Reporte para {cuenta} guardado como: {ruta_archivo}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error al generar reporte para {cuenta}: {str(e)}")
        return False

def main():
    print("üîÑ Iniciando lectura de feeds RSS...")
    
    # Crear carpeta principal de reportes si no existe
    os.makedirs('Reportes', exist_ok=True)
    
    # Cargar cuentas y sus temas
    print("\nüìä Cargando informaci√≥n de cuentas...")
    cuentas = cargar_cuentas()
    if not cuentas:
        print("‚ùå No se pudo cargar el archivo de cuentas. Saliendo...")
        return
    
    print(f"‚úÖ Se cargaron {len(cuentas)} cuentas")
    print("\nCuentas y temas cargados:")
    for cuenta, data in cuentas.items():
        print(f"‚Ä¢ {cuenta}: {len(data['temas'])} temas")
        for tema in data['temas']:
            print(f"  - {tema}")
    
    # Cargar temas del diccionario
    print("\nüìö Cargando diccionario de temas...")
    temas = cargar_diccionario()
    if not temas:
        print("‚ùå No se pudo cargar el diccionario de temas. Saliendo...")
        return
    
    print(f"‚úÖ Se cargaron {len(temas)} temas del diccionario")
    print("\nTemas cargados:")
    for tema, data in temas.items():
        print(f"‚Ä¢ {tema} ({len(data['palabras_clave'])} palabras clave)")
    
    # Configurar las fuentes RSS
    feeds = {
        'infobae': 'https://www.infobae.com/feeds/rss/',
        'clarin': 'https://www.clarin.com/rss/lo-ultimo/',
        'lanacion_principal': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/?outputType=xml',
        'lanacion_politica': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/categoria/politica/?outputType=xml',
        'lanacion_economia': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/categoria/economia/?outputType=xml',
        'lanacion_deportes': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/categoria/deportes/?outputType=xml',
        'lanacion_sociedad': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/categoria/sociedad/?outputType=xml',
        'lanacion_mundo': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/categoria/el-mundo/?outputType=xml',
        'lanacion_tecnologia': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/categoria/tecnologia/?outputType=xml',
        'lanacion_opinion': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/categoria/opinion/?outputType=xml',
        'lanacion_lifestyle': 'https://www.lanacion.com.ar/arc/outboundfeeds/rss/categoria/lifestyle/?outputType=xml',
        # La Pol√≠tica Online
        'lpo_ultimas': 'http://www.lapoliticaonline.com.ar/files/rss/ultimasnoticias.xml',
        'lpo_politica': 'http://www.lapoliticaonline.com.ar/files/rss/politica.xml',
        'lpo_economia': 'http://www.lapoliticaonline.com.ar/files/rss/economia.xml',
        # Feeds de medios regionales
        'misiones_online': 'https://misionesonline.net/feed/',
        'eldia': 'https://www.eldia.com/.rss',
        'rionegro': 'https://www.rionegro.com.ar/feed/',
        'diario_cuyo': 'https://www.diariodecuyo.com.ar/rss/rss.xml',
        # Feeds de La Gaceta
        'lagaceta_general': 'https://feeds.feedburner.com/LaGaceta-General',
        'lagaceta_politica': 'https://www.lagaceta.com.ar/rss/politica.xml',
        'lagaceta_economia': 'https://www.lagaceta.com.ar/rss/economia.xml',
        'lagaceta_deportes': 'https://www.lagaceta.com.ar/rss/deportes.xml',
        'lagaceta_sociedad': 'https://www.lagaceta.com.ar/rss/sociedad.xml',
        'lagaceta_mundo': 'https://www.lagaceta.com.ar/rss/mundo.xml',
        'lagaceta_espectaculos': 'https://www.lagaceta.com.ar/rss/espectaculos.xml',
        'lagaceta_opinion': 'https://www.lagaceta.com.ar/rss/opinion.xml',
        'pagina12': 'https://www.pagina12.com.ar/rss/portada',
        'cronista': 'https://www.cronista.com/files/rss/news.xml',
        'tn': 'https://tn.com.ar/rss',
        'mdz_politica': 'https://www.mdzol.com/rss/feed.html?r=1',
        'mdz_opinion': 'https://www.mdzol.com/rss/feed.html?r=4',
        'mdz_dinero': 'https://www.mdzol.com/rss/feed.html?r=5',
        'mdz_mundo': 'https://www.mdzol.com/rss/feed.html?r=6',
        'mdz_sociedad': 'https://www.mdzol.com/rss/feed.html?r=7',
        'mdz_deportes': 'https://www.mdzol.com/rss/feed.html?r=8',
        'mdz_sociales': 'https://www.mdzol.com/rss/feed.html?r=9',
        'mdz_show': 'https://www.mdzol.com/rss/feed.html?r=10',
        'mdz_espectaculos': 'https://www.mdzol.com/rss/feed.html?r=82',
        'mdz_policiales': 'https://www.mdzol.com/rss/feed.html?r=84',
        'mdz_energia': 'https://www.mdzol.com/rss/feed.html?r=90',
        # Feeds de √Åmbito Financiero
        'ambito_home': 'https://www.ambito.com/rss/pages/home.xml',
        'ambito_economia': 'https://www.ambito.com/rss/pages/economia.xml',
        'ambito_ultimas': 'https://www.ambito.com/rss/pages/ultimas-noticias.xml',
        'ambito_politica': 'https://www.ambito.com/rss/pages/politica.xml',
        'ambito_tecnologia': 'https://www.ambito.com/rss/pages/tecnologia.xml',
        # Feeds de La Voz
        'lavoz_principal': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?origen=1',
        'lavoz_noticias': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?origen=2',
        'lavoz_politica': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?categoria=1',
        'lavoz_negocios': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?categoria=48',
        'lavoz_ciudadanos': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?categoria=17',
        'lavoz_deportes': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?categoria=18',
        'lavoz_cultura': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?categoria=16',
        'lavoz_internacionales': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?categoria=47',
        'lavoz_espectaculos': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?categoria=213',
        'lavoz_opinion': 'http://archivo.lavoz.com.ar/RSS/RSS.asp?categoria=214',
    }
    
    all_news = []
    start_time = time.time()
    
    # Cargar noticias de Google Sheets
    sheet_news = cargar_noticias_sheets()
    all_news.extend(sheet_news)
    
    # Procesar feeds en paralelo
    print("\nüîÑ Procesando feeds en paralelo...")
    executor = concurrent.futures.ThreadPoolExecutor(max_workers=3)
    try:
        futures = [executor.submit(procesar_feed, (name, url)) for name, url in feeds.items()]
        
        for future in concurrent.futures.as_completed(futures):
            try:
                name, entries = future.result()
                if entries:
                    for entry in entries:
                        entry['feed_name'] = name
                        all_news.append(entry)
            except Exception as e:
                print(f"‚ùå Error inesperado: {str(e)}")
    finally:
        print("üîÑ Cerrando threads...")
        executor.shutdown(wait=True)
        print("‚úÖ Threads cerrados correctamente")
    
    tiempo_total = time.time() - start_time
    print(f"\n‚ú® Carga completada en {tiempo_total:.2f} segundos")
    
    # Clasificar noticias por tema
    print("\nüìä Clasificando noticias por tema...")
    noticias_por_tema = defaultdict(list)
    total_noticias_clasificadas = 0
    
    for noticia in all_news:
        temas_noticia = clasificar_noticia(noticia, temas)
        for tema_info in temas_noticia:
            tema = tema_info['tema']
            noticia['palabra_encontrada'] = tema_info['palabra_encontrada']
            noticias_por_tema[tema].append(noticia)
            total_noticias_clasificadas += 1
    
    # Mostrar resultados en consola
    print("\n=== NOTICIAS POR TEMA ===")
    for tema, noticias in noticias_por_tema.items():
        if noticias:
            print(f"\nüìå {tema.upper()} ({len(noticias)} noticias)")
            print("-" * 80)
            
            for noticia in noticias:
                fecha = noticia.get('published', 'Fecha no disponible')
                print(f"\n‚Ä¢ {noticia['title']}")
                print(f"  {noticia['feed_name']} - {fecha}")
                print(f"  Palabra clave encontrada: {noticia['palabra_encontrada']}")
                print(f"  {noticia['link']}")
            print("=" * 80)
    
    print(f"\nüìä Total de noticias clasificadas: {total_noticias_clasificadas}")
    
    # Generar reporte general
    print("\nüìù Generando reporte general...")
    guardar_en_word(noticias_por_tema, total_noticias_clasificadas, tiempo_total, feeds)
    
    # Generar reportes por cuenta
    print("\nüìù Generando reportes por cuenta...")
    reportes_generados = 0
    for cuenta, data in cuentas.items():
        print(f"\nüìå Procesando cuenta: {cuenta}")
        guardar_reporte_cuenta(cuenta, data['temas'], noticias_por_tema, tiempo_total, feeds)
        reportes_generados += 1
    
    print(f"\n‚ú® Proceso completado. Se generaron reportes para {reportes_generados} cuentas con noticias relevantes.")

if __name__ == "__main__":
    main() 